# app/streamlit_app.py
# Ù…Ø±Ø­Ù„Ù‡ 1/4: Ø§Ø³Ú©Ù„Øª Ø§Ù¾ + Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„/Ø¢Ø³ØªØ§Ù†Ù‡ + Ú†Ù‡Ø§Ø± ØªØ¨ Ø®Ø§Ù„ÛŒ
import os
import json
import io
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import joblib
import streamlit as st
import matplotlib.pyplot as plt

# ===== ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡ (Ø­ØªÙ…Ø§Ù‹ Ø§ÙˆÙ„ÛŒÙ† Ø¯Ø³ØªÙˆØ± Streamlit Ø¨Ø§Ø´Ø¯)
st.set_page_config(page_title="Credit Card Fraud Dashboard", layout="wide")

# ===== Ù…Ø³ÛŒØ±Ù‡Ø§
PROJECT_ROOT = Path(__file__).resolve().parents[1]  # .../Credit_Card_Fraud_Using_Pycaret
MODELS_DIR = PROJECT_ROOT / "models"

# ===== Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§
@st.cache_resource
def load_model(model_name: Optional[str] = None):
    """Ù…Ø¯Ù„ (Pipeline ÛŒØ§ Estimator) Ø±Ø§ Ø§Ø² Ù¾ÙˆØ´Ù‡ models Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯."""
    if model_name is None:
        model_path = MODELS_DIR / "best_model.pkl"
    else:
        model_path = MODELS_DIR / model_name
    if not model_path.exists():
        st.error(f"Ù…Ø¯Ù„ '{model_path.name}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§ÙˆÙ„ Ø¢Ù…ÙˆØ²Ø´ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù† Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± {MODELS_DIR} Ø¨Ø³Ø§Ø².")
        st.stop()
    model = joblib.load(model_path)
    return model

@st.cache_resource
def load_scaler():
    sc_path = MODELS_DIR / "scaler.pkl"
    if not sc_path.exists():
        st.error("scaler.pkl Ø¯Ø± Ù¾ÙˆØ´Ù‡ models Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø§Ø¨ØªØ¯Ø§ Ø¢Ù…ÙˆØ²Ø´ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†.")
        st.stop()
    return joblib.load(sc_path)

def read_metrics_summary():
    ms_path = MODELS_DIR / "metrics_summary.json"
    if not ms_path.exists():
        return None
    with open(ms_path, "r", encoding="utf-8") as f:
        return json.load(f)

def list_models():
    models = []
    if MODELS_DIR.exists():
        for p in MODELS_DIR.glob("*_model.pkl"):
            models.append(p.name)
    # Ù‡Ù…ÛŒØ´Ù‡ best_model Ø±Ø§ Ù‡Ù… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡
    if (MODELS_DIR / "best_model.pkl").exists():
        models = ["best_model.pkl"] + [m for m in models if m != "best_model.pkl"]
    return models

def preprocess_df(df: pd.DataFrame, scaler) -> pd.DataFrame:
    """Amount/Time Ø±Ø§ scale Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ù†Ø¨ÙˆØ¯ Ø¨Ø±Ø®ÛŒ VÙ‡Ø§ Ø±Ø§ Ø¨Ø§ ØµÙØ± Ù¾Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    df = df.copy()
    # Ø­Ø°Ù Ø³ØªÙˆÙ† Class Ø§Ú¯Ø± Ù‡Ø³Øª
    if "Class" in df.columns:
        df = df.drop(columns=["Class"])
    # Ú†Ú© Ø§Ù„Ø²Ø§Ù…Ø§Øª
    required_cols = ["Amount", "Time"]
    missing_req = [c for c in required_cols if c not in df.columns]
    if missing_req:
        st.error(f"Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ {missing_req} Ø¯Ø± ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù†Ø¯.")
        st.stop()
    # Ù¾Ø± Ú©Ø±Ø¯Ù† V1..V28 Ø§Ú¯Ø± Ú©Ù… Ø¯Ø§Ø±Ù†Ø¯
    v_cols = [f"V{i}" for i in range(1, 29)]
    for c in v_cols:
        if c not in df.columns:
            df[c] = 0.0
    # scale
    arr = scaler.transform(df[["Amount", "Time"]])
    df["scaled_amount"] = arr[:, 0]
    df["scaled_time"] = arr[:, 1]
    # Ø­Ø°Ù Amount/Time
    df = df.drop(columns=["Amount", "Time"])
    return df

def predict_df(model, X: pd.DataFrame, threshold: float):
    prob = model.predict_proba(X)[:, 1]
    pred = (prob >= threshold).astype(int)
    return prob, pred

# ===== Ø¹Ù†ÙˆØ§Ù†
st.title("ğŸ›¡ï¸ Credit Card Fraud Detection â€” Dashboard")

# ===== Ø³Ø§ÛŒØ¯Ø¨Ø§Ø±: Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ùˆ Ø¢Ø³ØªØ§Ù†Ù‡
with st.sidebar:
    st.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„")
    models = list_models()
    if not models:
        st.warning("Ù…Ø¯Ù„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø§Ø¨ØªØ¯Ø§ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø¢Ù…ÙˆØ²Ø´ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù† ØªØ§ Ù¾ÙˆØ´Ù‡ models Ø³Ø§Ø®ØªÙ‡ Ø´ÙˆØ¯.")
    model_choice = st.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„", options=models if models else ["(Ù†ÛŒØ³Øª)"], index=0)
    metrics_summary = read_metrics_summary()
    default_thr = 0.5
    if metrics_summary:
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡Ù” Ù‡Ù…Ø§Ù† Ù…Ø¯Ù„
        try:
            if model_choice == "best_model.pkl":
                best_name = metrics_summary.get("best_model")
                if best_name and "thresholds" in metrics_summary:
                    default_thr = float(metrics_summary["thresholds"][best_name]["t"] if "t" in metrics_summary["thresholds"][best_name] 
                                        else metrics_summary["thresholds"][best_name]["best_threshold"])
            else:
                key = model_choice.replace("_model.pkl", "")
                throbj = metrics_summary.get("thresholds", {}).get(key)
                if throbj:
                    default_thr = float(throbj.get("t", throbj.get("best_threshold", 0.5)))
        except Exception:
            pass
    threshold = st.slider("Threshold", min_value=0.0, max_value=1.0, value=float(default_thr), step=0.01)
    st.caption("Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÛŒ Ø¨Ø²Ø±Ú¯â€ŒØªØ± â†’ Precision Ø¨Ø§Ù„Ø§ØªØ± / Recall Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±. Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± â†’ Recall Ø¨Ø§Ù„Ø§ØªØ± / Precision Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±.")

# Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ùˆ Ø§Ø³Ú©Ù„Ø±
if models:
    model = load_model(None if model_choice == "best_model.pkl" else model_choice)
    scaler = load_scaler()
else:
    model = None
    scaler = None
# === Helpers for analytics and inspection ===
from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve, auc

def evaluate_if_labeled(df_with_preds: pd.DataFrame):
    """
    Ø§Ú¯Ø± Ø³ØªÙˆÙ† Class ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ùˆ Ù…Ù†Ø­Ù†ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø­Ø³Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø®Ø±ÙˆØ¬ÛŒ: dict Ø´Ø§Ù…Ù„ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ùˆ Ù†Ù‚Ø§Ø· ROC/PR
    """
    if "Class" not in df_with_preds.columns:
        return None
    y_true = df_with_preds["Class"].astype(int).values
    y_prob = df_with_preds["fraud_prob"].values
    y_pred = df_with_preds["fraud_pred"].astype(int).values

    metrics = {
        "roc_auc": float(roc_auc_score(y_true, y_prob)),
        "pr_auc":  float(average_precision_score(y_true, y_prob)),
    }
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    prec, rec, thr = precision_recall_curve(y_true, y_prob)

    curves = {"fpr": fpr, "tpr": tpr, "prec": prec, "rec": rec, "thr": thr}
    return {"metrics": metrics, "curves": curves}

def plot_roc(ax, fpr, tpr, title="ROC Curve"):
    ax.plot(fpr, tpr, lw=2)
    ax.plot([0,1],[0,1],"--", lw=1)
    ax.set_xlabel("False Positive Rate")
    ax.set_ylabel("True Positive Rate")
    ax.set_title(title)
    ax.grid(alpha=0.3)

def plot_pr(ax, rec, prec, title="Precision-Recall"):
    ax.plot(rec, prec, lw=2)
    ax.set_xlabel("Recall")
    ax.set_ylabel("Precision")
    ax.set_title(title)
    ax.grid(alpha=0.3)

def feature_importance_df(model, feature_names: list):
    """Ø¨Ø±Ú¯Ø´Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ RF/XGB/LGBM ÛŒØ§ Ø¶Ø±Ø§ÛŒØ¨ LogReg"""
    if hasattr(model, "feature_importances_"):
        vals = model.feature_importances_
        return pd.DataFrame({"feature": feature_names, "importance": vals}).sort_values("importance", ascending=False)
    if hasattr(model, "coef_"):
        coefs = np.ravel(model.coef_)
        return pd.DataFrame({"feature": feature_names, "importance": np.abs(coefs), "coef": coefs}).sort_values("importance", ascending=False)
    return None

# ===== ØªØ¨â€ŒÙ‡Ø§
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“¥ Predict CSV",
    "ğŸ“Š Analytics & Charts",
    "ğŸ§¾ Single Transaction",
    "ğŸ§  Model & Threshold"
])

# ÙØ¹Ù„Ø§Ù‹ Ù…Ø­ØªÙˆØ§ Ø®Ø§Ù„ÛŒâ€”Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡Ù” Ø¨Ø¹Ø¯ Tab1 Ø±Ø§ Ú©Ø§Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
with tab1:
    st.subheader("ğŸ“¥ Predict on CSV")

    up = st.file_uploader("ÛŒÚ© ÙØ§ÛŒÙ„ CSV Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Amount, Time, V1..V28 Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†", type=["csv"])
    if up is not None and model is not None and scaler is not None:
        # Ø®ÙˆØ§Ù†Ø¯Ù†
        df_in = pd.read_csv(up)
        st.write("Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:", df_in.head())

        # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
        try:
            X = preprocess_df(df_in, scaler)
        except Exception as e:
            st.error(str(e))
            st.stop()

        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        prob, pred = predict_df(model, X, threshold)
        out = df_in.copy()
        out["fraud_prob"] = prob
        out["fraud_pred"] = pred

        # Ù†Ù…Ø§ÛŒØ´ Ø®Ø±ÙˆØ¬ÛŒ
        st.success("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ âœ…")
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§", len(out))
        with c2:
            st.metric("Ù…Ø´Ú©ÙˆÚ© (pred=1)", int(out["fraud_pred"].sum()))
        with c3:
            ratio = 100.0 * (out["fraud_pred"].sum() / max(1, len(out)))
            st.metric("Ø¯Ø±ØµØ¯ Ù…Ø´Ú©ÙˆÚ©", f"{ratio:.3f}%")

        st.write("Ú†Ù†Ø¯ Ø±Ø¯ÛŒÙ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ø®Ø±ÙˆØ¬ÛŒ:")
        st.dataframe(out.head(20), use_container_width=True)

        # Ø¯Ø§Ù†Ù„ÙˆØ¯
        csv_buf = io.StringIO()
        out.to_csv(csv_buf, index=False)
        st.download_button(
            "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†ØªØ§ÛŒØ¬ (CSV)",
            data=csv_buf.getvalue(),
            file_name="predictions.csv",
            mime="text/csv"
        )

    # === Histogram of predicted fraud probabilities (enhanced with zoom & controls) ===
    st.markdown("### Histogram of Predicted Fraud Probabilities")

    if "out" in locals():
        probs = out["fraud_prob"].values

        # Ú©Ù†ØªØ±Ù„â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ÛŒ
        c1, c2, c3 = st.columns([2, 1.5, 1.5])
        with c1:
            zoom_range = st.slider("Zoom range (X-axis)", 0.0, 1.0, (0.0, 1.0), 0.01)
        with c2:
            bins = st.slider("Number of bins", 20, 200, 100, 5)
        with c3:
            yscale = st.selectbox("Y-axis scale", ["log", "linear"], index=0)

        # ÙÛŒÙ„ØªØ± Ø¨Ø§Ø²Ù‡
        mask = (probs >= zoom_range[0]) & (probs <= zoom_range[1])
        probs_view = probs[mask]

        if len(probs_view) == 0:
            st.warning("Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ù‡ÛŒÚ† Ù…Ù‚Ø¯Ø§Ø±ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ø¨Ø§Ø²Ù‡ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡.")
        else:
            fig, ax = plt.subplots(figsize=(8, 4))
            vals, bins_edges, patches = ax.hist(
                probs_view,
                bins=bins,
                color="steelblue",
                alpha=0.8,
                edgecolor="white"
            )

            # Ù…Ù‚ÛŒØ§Ø³ Ù„Ú¯Ø§Ø±ÛŒØªÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±
            if yscale == "log":
                ax.set_yscale("log")

            # Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø§Ù„Ø§ Ø¯Ø§Ø±Ù†Ø¯
            centers = 0.5 * (bins_edges[:-1] + bins_edges[1:])
            for c, p in zip(centers, patches):
                if c >= threshold:
                    p.set_facecolor("crimson")

            # Ù†Ù…Ø§ÛŒØ´ Ø®Ø·ÙˆØ· Ø¢Ù…Ø§Ø±ÛŒ
            mean_val = probs_view.mean()
            median_val = np.median(probs_view)
            ax.axvline(mean_val, color="orange", linestyle="--", lw=2, label=f"Mean = {mean_val:.3f}")
            ax.axvline(median_val, color="green", linestyle="--", lw=2, label=f"Median = {median_val:.3f}")
            ax.axvline(threshold, color="crimson", linestyle="--", lw=2, label=f"Threshold = {threshold:.2f}")

            # Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ùˆ Ø¸Ø§Ù‡Ø±
            ax.set_title("Histogram of Predicted Fraud Probabilities (Zoomable)")
            ax.set_xlabel("Fraud Probability")
            ax.set_ylabel("Count" + (" (log scale)" if yscale == "log" else ""))
            ax.grid(alpha=0.3)
            ax.legend()

            st.pyplot(fig)

            # Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±ÛŒ
            n_total = len(probs_view)
            n_high = int((probs_view >= threshold).sum())
            c1, c2, c3 = st.columns(3)
            c1.metric("Samples in view", n_total)
            c2.metric("â‰¥ Threshold", n_high)
            c3.metric("% High-risk", f"{100.0 * n_high / max(1, n_total):.3f}%")

            # Ù†Ù…ÙˆØ¯Ø§Ø± ØªØ¬Ù…Ø¹ÛŒ (Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ú© ØªÙˆØ²ÛŒØ¹ Ø¯ÙÙ…)
            st.markdown("#### Cumulative Distribution (CCDF)")
            xs = np.sort(probs_view)
            ccdf = 1.0 - np.arange(1, len(xs) + 1) / len(xs)
            fig2, ax2 = plt.subplots(figsize=(8, 3))
            ax2.plot(xs, ccdf, lw=2)
            if yscale == "log":
                ax2.set_yscale("log")
            ax2.axvline(threshold, color="crimson", linestyle="--", lw=2)
            ax2.set_xlabel("Fraud Probability")
            ax2.set_ylabel("Fraction â‰¥ x")
            ax2.set_title("CCDF of Fraud Probabilities")
            ax2.grid(alpha=0.3)
            st.pyplot(fig2)

            st.caption("""
            **Ø±Ø§Ù‡Ù†Ù…Ø§:**  
            - Ø§Ø² Ø§Ø³Ù„Ø§ÛŒØ¯Ø± **Zoom range** Ø¨Ø±Ø§ÛŒ Ø²ÙˆÙ… Ø±ÙˆÛŒ Ø¨Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† (Ù…Ø«Ù„Ø§Ù‹ 0.05â€“1.0).  
            - Ù…Ø­ÙˆØ± **Y (log)** Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ù‡Ù… Ø¯ÛŒØ¯Ù‡ Ø¨Ø´Ù†.  
            - Ù†ÙˆØ§Ø±Ù‡Ø§ÛŒ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†Ù‡â€ŒÛŒ ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø§Ù„Ø§ÛŒ Ø¢Ø³ØªØ§Ù†Ù‡ ÙØ¹Ù„ÛŒ Ù‡Ø³ØªÙ†.  
            - Ø®Ø·ÙˆØ· Ù†Ø§Ø±Ù†Ø¬ÛŒ Ùˆ Ø³Ø¨Ø² Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ùˆ Ù…ÛŒØ§Ù†Ù‡â€ŒÛŒ Ø§Ø­ØªÙ…Ø§Ù„â€ŒÙ‡Ø§ Ø±Ùˆ Ù†Ø´ÙˆÙ† Ù…ÛŒâ€ŒØ¯Ù†.
            """)
    else:
        st.info("ÙØ§ÛŒÙ„ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù† ØªØ§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.")



with tab2:
    st.subheader("ğŸ“Š Analytics & Charts")

    st.caption("Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± ØªØ¨ Â«Predict CSVÂ» ÙØ§ÛŒÙ„ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ú¯ÛŒØ±ÛŒØ¯Ø› Ø§ÛŒÙ†Ø¬Ø§ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø±ÛŒ Ø±ÙˆÛŒ Ù‡Ù…Ø§Ù† Ø®Ø±ÙˆØ¬ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

    if "out" in locals():
        # out Ù‡Ù…Ø§Ù† Ø®Ø±ÙˆØ¬ÛŒ ØªØ¨ 1 Ø§Ø³Øª (df ÙˆØ±ÙˆØ¯ÛŒ + fraud_prob + fraud_pred)
        df_out = out.copy()

        c1, c2, c3, c4 = st.columns(4)
        with c1:
            st.metric("Total rows", len(df_out))
        with c2:
            st.metric("Predicted Fraud (1)", int(df_out["fraud_pred"].sum()))
        with c3:
            st.metric("Avg fraud prob", f"{df_out['fraud_prob'].mean():.4f}")
        with c4:
            st.metric("Max fraud prob", f"{df_out['fraud_prob'].max():.4f}")

        st.markdown("---")

        # Distribution charts
        cL, cR = st.columns([2, 1])
        with cL:
            fig, ax = plt.subplots(figsize=(7,3))
            ax.hist(df_out["fraud_prob"], bins=50)
            ax.set_title("Histogram of predicted fraud probabilities")
            ax.set_xlabel("fraud_prob")
            ax.set_ylabel("count")
            ax.grid(alpha=0.3)
            st.pyplot(fig)

        with cR:
            counts = df_out["fraud_pred"].value_counts().reindex([0,1], fill_value=0)
            fig, ax = plt.subplots(figsize=(4,3))
            ax.pie(counts.values, labels=["Not Fraud", "Fraud"], autopct="%1.2f%%", startangle=90)
            ax.set_title("Fraud vs Not Fraud (pred)")
            st.pyplot(fig)

        # Amount bins vs fraud rate
        st.markdown("### Fraud rate by Amount bins")
        try:
            bins = st.slider("Number of bins", 5, 50, 10, 1)
            df_tmp = df_out.copy()
            if "Amount" in df_tmp.columns:
                df_tmp["amount_bin"] = pd.qcut(df_tmp["Amount"], q=bins, duplicates="drop")
                grp = df_tmp.groupby("amount_bin")["fraud_pred"].mean().reset_index()
                fig, ax = plt.subplots(figsize=(10,3))
                ax.bar(range(len(grp)), grp["fraud_pred"].values)
                ax.set_xticks(range(len(grp)))
                ax.set_xticklabels([str(x) for x in grp["amount_bin"]], rotation=60, ha="right")
                ax.set_ylabel("Fraud rate (pred)")
                ax.set_title("Fraud rate by transaction amount (quantile bins)")
                ax.grid(axis="y", alpha=0.3)
                st.pyplot(fig)
            else:
                st.info("Ø³ØªÙˆÙ† Amount Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ø¢Ù¾Ù„ÙˆØ¯ÛŒ Ù†Ø¨ÙˆØ¯Ø› Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ Ø±Ø¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….")
        except Exception as e:
            st.warning(f"ØªØ­Ù„ÛŒÙ„ Amount Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯: {e}")

        # Top-K suspicious
        st.markdown("### Top-K suspicious transactions")
        K = st.slider("Top-K", 5, 100, 20, 1)
        st.dataframe(df_out.sort_values("fraud_prob", ascending=False).head(K), use_container_width=True)

        st.markdown("---")

        # If labeled, show ROC/PR on uploaded set
        eval_res = evaluate_if_labeled(df_out)
        if eval_res is not None:
            st.markdown("### Evaluation on uploaded CSV (ground-truth detected)")
            met = eval_res["metrics"]
            curves = eval_res["curves"]
            c1, c2 = st.columns(2)
            with c1:
                st.metric("ROC AUC (uploaded)", f"{met['roc_auc']:.4f}")
            with c2:
                st.metric("PR AUC (uploaded)", f"{met['pr_auc']:.4f}")

            fig, ax = plt.subplots(figsize=(5,4))
            plot_roc(ax, curves["fpr"], curves["tpr"], title="ROC (uploaded)")
            st.pyplot(fig)

            fig, ax = plt.subplots(figsize=(5,4))
            plot_pr(ax, curves["rec"], curves["prec"], title="Precision-Recall (uploaded)")
            st.pyplot(fig)
        else:
            st.info("Ø¨Ø±Ú†Ø³Ø¨ ÙˆØ§Ù‚Ø¹ÛŒ (Ø³ØªÙˆÙ† Class) Ø¯Ø± ÙØ§ÛŒÙ„ Ù†Ø¨ÙˆØ¯Ø› Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ROC/PR Ø±ÙˆÛŒ ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ÛŒ Ù‚Ø§Ø¨Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ÛŒØ³Øª.")
    else:
        st.info("Ø§Ø¨ØªØ¯Ø§ ØªØ¨ Â«Predict CSVÂ» Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù† ØªØ§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.")


with tab3:
    st.subheader("ğŸ§¾ Single Transaction Tester")

    if model is None or scaler is None:
        st.warning("Ù…Ø¯Ù„/Ø§Ø³Ú©Ù„Ø± Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡. Ø¨Ù‡ Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ù†Ú¯Ø§Ù‡ Ú©Ù†.")
        st.stop()

    st.caption("Ø­Ø¯Ø§Ù‚Ù„ Amount Ùˆ Time Ù„Ø§Ø²Ù… Ø§Ø³Øª. Ø§Ú¯Ø± VÙ‡Ø§ Ø±Ø§ Ù†Ø¯Ù‡ÛŒØŒ ØµÙØ± Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

    # ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ú¯Ø±ÛŒØ¯
    cols_top = st.columns(4)
    Amount = cols_top[0].number_input("Amount", value=100.0, step=1.0)
    Time   = cols_top[1].number_input("Time", value=50000.0, step=100.0)
    default_fill_zero = cols_top[2].checkbox("Fill missing V1..V28 with 0", value=True)
    show_v = cols_top[3].checkbox("Show V1..V28 inputs", value=False)

    v_vals = {}
    if show_v:
        # 28 ÙˆÛŒÚ˜Ú¯ÛŒ Ø±Ø§ Ø¯Ø± 4 Ø³ØªÙˆÙ† ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        grid = [st.columns(4) for _ in range(7)]  # 7 Ø±Ø¯ÛŒÙ Ã— 4 Ø³ØªÙˆÙ† = 28
        idx = 0
        for r in range(7):
            for c in range(4):
                vi = idx + 1
                v_vals[f"V{vi}"] = grid[r][c].number_input(f"V{vi}", value=0.0, step=0.1, format="%.4f")
                idx += 1
    else:
        if default_fill_zero:
            for i in range(1, 29):
                v_vals[f"V{i}"] = 0.0

    if st.button("Predict"):
        row = {"Amount": Amount, "Time": Time, **v_vals}
        df_one = pd.DataFrame([row])

        # preprocess
        arr = scaler.transform(df_one[["Amount","Time"]])
        df_one["scaled_amount"] = arr[:, 0]
        df_one["scaled_time"]   = arr[:, 1]
        X = df_one.drop(columns=["Amount","Time"])

        # predict
        prob = float(model.predict_proba(X)[:, 1][0])
        pred = int(prob >= threshold)

        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("Fraud Probability", f"{prob:.4f}")
        with c2:
            st.metric("Prediction", "FRAUD" if pred==1 else "OK")
        with c3:
            st.metric("Threshold used", f"{threshold:.2f}")

        # Progress bar Ø¨Ø±Ø§ÛŒ Ø­Ø³ Ø¨Ù‡ØªØ±
        st.progress(min(max(prob, 0.0), 1.0))


with tab4:
    st.subheader("ğŸ§  Model & Threshold Inspector")

    if model is None or scaler is None:
        st.warning("Ù…Ø¯Ù„/Ø§Ø³Ú©Ù„Ø± Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡.")
        st.stop()

    # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø®Ù„Ø§ØµÙ‡ Ø§Ø² ÙØ§ÛŒÙ„ metrics_summary.json
    ms = read_metrics_summary()
    if ms:
        best_name = ms.get("best_model", None)
        st.write("**Best model (from training):**", best_name if best_name else "-")

        # Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª summary Ù‚Ø¯ÛŒÙ…ÛŒ (Ù†Ø³Ø®Ù‡ Ù‚Ø¨Ù„ÛŒ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ©) Ø¨Ø§Ø´Ø¯
        # Ø¯Ùˆ Ø­Ø§Ù„Øª Ø§Ø³Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ Ø±Ø§ Ù‡Ù†Ø¯Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:
        if "summary" in ms:
            df_sum = pd.DataFrame(ms["summary"]).T
        elif "global" in ms:
            df_sum = pd.DataFrame(ms["global"]).T
        else:
            df_sum = None

        if df_sum is not None:
            st.markdown("**Training summary:**")
            st.dataframe(df_sum, use_container_width=True)

        st.caption("Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù…ØªØ±ÛŒÚ© Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ø³Ø§Ø®ØªØ§Ø± Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯ØŒ Ø¬Ø¯ÙˆÙ„ Ø¨Ø§Ù„Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯.")
    else:
        st.info("metrics_summary.json Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")

    st.markdown("---")

    # Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
    # Ø³Ø§Ø®Øª Ù„ÛŒØ³Øª Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ù…Ø·Ø§Ø¨Ù‚ preprocess_df: V1..V28 + scaled_amount + scaled_time
    feature_names = [f"V{i}" for i in range(1, 29)] + ["scaled_amount", "scaled_time"]
    fi = feature_importance_df(model, feature_names)
    if fi is not None:
        st.markdown("### Feature Importance / Coefficients")
        st.dataframe(fi.head(30), use_container_width=True)

        fig, ax = plt.subplots(figsize=(7, 5))
        head = fi.head(15)
        ax.barh(head["feature"][::-1], head["importance"][::-1])
        ax.set_title("Top-15 Feature Importance")
        ax.set_xlabel("Importance (abs coef or split gain)")
        st.pyplot(fig)
    else:
        st.info("Ø§ÛŒÙ† Ù…Ø¯Ù„ ÙÛŒÚ†Ø± Ø§ÛŒÙ…Ù¾ÙˆØ±ØªÙ†Ø³/Ø¶Ø±ÛŒØ¨ Ù‚Ø§Ø¨Ù„ Ù†Ù…Ø§ÛŒØ´ Ù†Ø¯Ø§Ø±Ø¯.")

    st.markdown("---")
    st.markdown("### Threshold tips")
    st.write(
        """
        - Ø¢Ø³ØªØ§Ù†Ù‡Ù” Ø¨Ø²Ø±Ú¯â€ŒØªØ± â†’ **Precision** Ø¨ÛŒØ´ØªØ±ØŒ **Recall** Ú©Ù…ØªØ± (Ù…Ù†Ø§Ø³Ø¨ Ú©Ø§Ù‡Ø´ Ø¢Ù„Ø§Ø±Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø´ØªØ¨Ø§Ù‡).
        - Ø¢Ø³ØªØ§Ù†Ù‡Ù” Ú©ÙˆÚ†Ú©â€ŒØªØ± â†’ **Recall** Ø¨ÛŒØ´ØªØ±ØŒ **Precision** Ú©Ù…ØªØ± (Ù…Ù†Ø§Ø³Ø¨ Ú©Ø´Ù Ø­Ø¯Ø§Ú©Ø«Ø±ÛŒ).
        - Ø¯Ø± Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ø¢Ø³ØªØ§Ù†Ù‡ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ùˆ Ø¯Ø± ØªØ¨ Ø§ÙˆÙ„ Ùˆ Ø³ÙˆÙ… Ø±ÙØªØ§Ø± Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø¨ÛŒÙ†.
        """
    )

